{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "9e37f8c668a047ea95364d2af1f64e75",
        "source_hash": "cee039e2",
        "owner_user_id": "55930dec-6eb8-47d6-b7f8-52db6ea4b88a",
        "execution_start": 1654073238684,
        "execution_millis": 9975,
        "deepnote_cell_height": 1035,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "zoeibsVmD6Eo"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import wandb\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "import random\n",
        "import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import concat\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Input, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, Huber, MeanSquaredError\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow import reshape\n",
        "\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.specs import array_spec, tensor_spec\n",
        "from tf_agents.utils import common\n",
        "\n",
        "from spektral.layers import XENetDenseConv\n",
        "from spektral.transforms import LayerPreprocess\n",
        "from spektral.utils.sparse import sp_matrix_to_sp_tensor\n",
        "from spektral.data import Graph\n",
        "from spektral.data.dataset import Dataset\n",
        "from spektral.data.loaders import BatchLoader\n",
        "\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "from collections import deque\n",
        "from random import sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "8a38a5d358a84977b0a5164853498406",
        "source_hash": "914795f7",
        "execution_start": 1654073272732,
        "execution_millis": 2311,
        "deepnote_cell_height": 701,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "u_cfiBSFD6Eu"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "e44e2c9a9b9e4287ad0eb24b47079b2b",
        "source_hash": "2b9dfce8",
        "execution_start": 1654006794209,
        "execution_millis": 512,
        "deepnote_cell_height": 190.375,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "NOvKVfWmD6Ew",
        "outputId": "d8e7536f-e1db-47d4-b5a8-46c9e156674d"
      },
      "source": [
        "# RANDOM_SEED = 5\n",
        "# tf.random.set_seed(RANDOM_SEED)\n",
        "# env.seed(RANDOM_SEED)\n",
        "# np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "0e16b7e15e2f40dba44b82f7aff2acdd",
        "source_hash": "a6b6d43a",
        "execution_start": 1654006794272,
        "execution_millis": 457,
        "deepnote_cell_height": 1541.9375,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "ZDBo4n6yD6Ex",
        "outputId": "8d216851-16fe-4c11-f44e-b5defe2f0b21"
      },
      "source": [
        "sweep_config = {\n",
        "    \"name\": 'First run',\n",
        "    'method':'random'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name' : 'loss',\n",
        "    'goal' : 'minimize'\n",
        "}\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'N_xenet': {\n",
        "        'value': 1\n",
        "    },\n",
        "    'N_dense': {\n",
        "        'distribution': 'int_uniform',\n",
        "        'min': 0,\n",
        "        'max': 10\n",
        "    },\n",
        "    'division_factor_dense': {\n",
        "        'value': 1\n",
        "    },\n",
        "    'stack_channels': {\n",
        "        'distribution': 'int_uniform',\n",
        "        'min': 3,\n",
        "        'max': 20\n",
        "    },\n",
        "    'node_channels': {\n",
        "        'distribution': 'int_uniform',\n",
        "        'min': 3,\n",
        "        'max': 20\n",
        "    },\n",
        "    'edge_channels': {\n",
        "        'distribution': 'int_uniform',\n",
        "        'min': 3,\n",
        "        'max': 20\n",
        "    },\n",
        "    'train_episodes': {\n",
        "        'value': 100\n",
        "    },\n",
        "    'MIN_REPLAY_SIZE': {\n",
        "        'value': 32\n",
        "    },\n",
        "    'batch_size': {\n",
        "        'value': 32\n",
        "    },\n",
        "    'step_buffer': {\n",
        "        'distribution': 'int_uniform',\n",
        "        'min': 3,\n",
        "        'max': 20\n",
        "    }\n",
        "\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'method': 'random',\n 'metric': {'goal': 'minimize', 'name': 'loss'},\n 'name': 'First run',\n 'parameters': {'MIN_REPLAY_SIZE': {'value': 32},\n                'N_dense': {'distribution': 'int_uniform', 'max': 10, 'min': 0},\n                'N_xenet': {'value': 1},\n                'batch_size': {'value': 32},\n                'division_factor_dense': {'value': 1},\n                'edge_channels': {'distribution': 'int_uniform',\n                                  'max': 20,\n                                  'min': 3},\n                'node_channels': {'distribution': 'int_uniform',\n                                  'max': 20,\n                                  'min': 3},\n                'stack_channels': {'distribution': 'int_uniform',\n                                   'max': 20,\n                                   'min': 3},\n                'step_buffer': {'distribution': 'int_uniform',\n                                'max': 20,\n                                'min': 3},\n                'train_episodes': {'value': 100}}}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "d07d995552684d4a8c7231cf40147678",
        "source_hash": "9cefcc18",
        "execution_start": 1654006794370,
        "execution_millis": 3029,
        "deepnote_cell_height": 152.5625,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "SqB5WqyDD6Ey",
        "outputId": "60043a40-6002-42c0-8e73-57eda2f86c67"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"randomSearch-project\", entity=\"locp\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\nCreate sweep with ID: ws8ob6ro\nSweep URL: https://wandb.ai/locp/randomSearch-project/sweeps/ws8ob6ro\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "43e993ecc54c4bb48f1588be155e027d",
        "deepnote_cell_height": 255.125,
        "deepnote_cell_type": "markdown",
        "id": "_nGYvijID6Ez"
      },
      "source": [
        "parameters\n",
        "- number of train_episodes\n",
        "- size of replay_memory\n",
        "- update steps of main and target network\n",
        "- learning_rate\n",
        "- discount_factor\n",
        "- MIN_REPLAY_SIZE (minimum size of the replay_memory for which we do the training)\n",
        "- batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "0c1a26e3e28d43daa1b363d0ae19c31d",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "5LhIYKUED6E1"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "05e8298bf009466395e4f18fe17afb93",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "nAEPv1CXD6E2"
      },
      "source": [
        "### Predefined Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "0174e8d88c2a4e0cbed98751fb113496",
        "deepnote_cell_height": 54,
        "deepnote_cell_type": "markdown",
        "id": "NL4Vt89bD6E3"
      },
      "source": [
        "##### Sparse Matrix Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "ac28fbe2bd6c426c807b225931719771",
        "source_hash": "3851d35b",
        "execution_start": 1654006797200,
        "execution_millis": 219,
        "deepnote_cell_height": 568.375,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "NGk8gcneD6E4",
        "outputId": "2dbd6d92-6bab-4dab-8cee-a09a86d5f034"
      },
      "source": [
        "def sparseAdj(D, L):\n",
        "    N = L**D\n",
        "    nodes = [x for x in np.ndindex(tuple(np.repeat(L,D)))]\n",
        "    mul = [L**i for i in reversed(range(D))]\n",
        "\n",
        "    A_dense = []\n",
        "    for node in nodes:\n",
        "        temp_buffer = []\n",
        "        A_dense_row = [0]*N\n",
        "        for d in range(D):\n",
        "            temp=list(node)\n",
        "            temp[d]=((temp[d]+1)%L)\n",
        "            temp=np.inner(temp, mul)\n",
        "            temp_buffer.append(temp)\n",
        "\n",
        "            temp=list(node)\n",
        "            temp[d]=((temp[d]-1)%L)\n",
        "            temp=np.inner(temp, mul)\n",
        "            temp_buffer.append(temp)\n",
        "\n",
        "        temp_buffer=list(np.unique(np.array(temp_buffer), axis=0))\n",
        "        for i in temp_buffer: A_dense_row[i]=1\n",
        "        A_dense.append(A_dense_row)\n",
        "\n",
        "    return sp_matrix_to_sp_tensor(np.array(A_dense))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "acb3913f0a064c19a44c82196c0c4031",
        "source_hash": "b8379f55",
        "execution_start": 1654006797281,
        "execution_millis": 1,
        "deepnote_cell_height": 513,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "NWXqhAJXD6E4"
      },
      "source": [
        "def denseAdj(D, L):\n",
        "    N = L**D\n",
        "    nodes = [x for x in np.ndindex(tuple(np.repeat(L,D)))]\n",
        "    mul = [L**i for i in reversed(range(D))]\n",
        "\n",
        "    A_dense = []\n",
        "    for node in nodes:\n",
        "        temp_buffer = []\n",
        "        A_dense_row = [0]*N\n",
        "        for d in range(D):\n",
        "            temp=list(node)\n",
        "            temp[d]=((temp[d]+1)%L)\n",
        "            temp=np.inner(temp, mul)\n",
        "            temp_buffer.append(temp)\n",
        "\n",
        "            temp=list(node)\n",
        "            temp[d]=((temp[d]-1)%L)\n",
        "            temp=np.inner(temp, mul)\n",
        "            temp_buffer.append(temp)\n",
        "\n",
        "        temp_buffer=list(np.unique(np.array(temp_buffer), axis=0))\n",
        "        for i in temp_buffer: A_dense_row[i]=1\n",
        "        A_dense.append(A_dense_row)\n",
        "\n",
        "    return np.array(A_dense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "b1d99f8b15514e30ac2e46eaee348f90",
        "source_hash": "12bd05f0",
        "execution_start": 1654006797288,
        "execution_millis": 4,
        "deepnote_cell_height": 513,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "lPNxEIhsD6E5"
      },
      "source": [
        "def J_inter(denseAdj):\n",
        "    N = denseAdj.shape[0]\n",
        "    sparseAdj = sp_matrix_to_sp_tensor(denseAdj)\n",
        "    edge=sparseAdj.indices.numpy()\n",
        "    un_edge=np.array([np.sort(i) for i in edge])\n",
        "    inter=[]\n",
        "    for i in range(len(un_edge)):\n",
        "        equal=True\n",
        "        for j in range(i):\n",
        "            if np.array_equal(un_edge[i],un_edge[j]):\n",
        "                inter.append(inter[j])\n",
        "                equal=False\n",
        "                break\n",
        "        if equal:\n",
        "            inter.append(np.random.normal(0, 1))\n",
        "\n",
        "    inter_matrix = np.zeros((N,N))\n",
        "    counter = 0\n",
        "    for i, j in edge:\n",
        "        inter_matrix[i,j] = inter[counter]\n",
        "        counter += 1\n",
        "    return [np.array(inter).reshape(sparseAdj.indices.shape[0],1), inter_matrix.reshape((N,N,1))]\n",
        "\n",
        "    # 0 => interaction array\n",
        "    # 1 => interaction matrix (zero padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "35dcb74fafa8456f89ea1fc978920dae",
        "source_hash": "6df8e1ad",
        "execution_start": 1654006797304,
        "execution_millis": 82,
        "deepnote_cell_height": 1611,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "c3ZHQFn_D6E5"
      },
      "source": [
        "class SG_env(py_environment.PyEnvironment):\n",
        "\n",
        "  def __init__(self, L, D):\n",
        "\n",
        "    self.N = L**D\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=self.N-1, name='action')\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(self.N,1), dtype=np.int32, minimum=-1, maximum=1, name='observation')\n",
        "    self.sp_AdjMat = sparseAdj(D=D, L=L)\n",
        "    self.dense_AdjMat = denseAdj(D=D, L=L)\n",
        "    self.interaction = J_inter(self.dense_AdjMat)[0]    # self.sp_AdjMat.indices.shape[0]=2*D*N\n",
        "    self.inter_matrix = J_inter(self.dense_AdjMat)[1]\n",
        "    self._state = np.ones(shape=(self.N,1)).astype(\"int32\")\n",
        "    self._episode_ended = False\n",
        "\n",
        "  def get_state(self):\n",
        "    return self._state\n",
        "\n",
        "  def show_N(self):\n",
        "    return self.N\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def show_dense_AdjMat(self):\n",
        "    return self.dense_AdjMat\n",
        "\n",
        "  def show_sp_AdjMat(self):\n",
        "    return self.sp_AdjMat\n",
        "\n",
        "  def show_interaction(self):\n",
        "    return self.interaction\n",
        "\n",
        "  def show_inter_matrix(self):\n",
        "    return self.inter_matrix\n",
        "\n",
        "  def __all_spins_down(self):\n",
        "    return np.all(self._state==-1)    # True => All spins = -1, False otherwise\n",
        "\n",
        "  def computeReward(self, action):\n",
        "    nns = self.sp_AdjMat.indices[self.sp_AdjMat.indices[:,0]==action][:,1].numpy()\n",
        "    nn_Js = np.where(self.sp_AdjMat.indices[:,0]==action)[0]\n",
        "    nn_sum = 0\n",
        "    for i in range(len(nns)): nn_sum += self.interaction[nn_Js[i]]*self._state[nns[i],0]\n",
        "    reward = -2*nn_sum*self._state[action,0]\n",
        "    return reward[0]\n",
        "\n",
        "  def computeEnergy(self):\n",
        "    edge = self.sp_AdjMat.indices.numpy()\n",
        "    Nedge = len(edge)\n",
        "    energy = 0\n",
        "    for i in range(Nedge):\n",
        "        energy -= self.interaction[i][0]*self._state[edge[i][0]][0]*self._state[edge[i][1]][0]\n",
        "    return energy/2\n",
        "\n",
        "  def _reset(self):\n",
        "    self._state = np.ones(shape=(self.N,1)).astype(\"int32\")\n",
        "    #self.interaction = J_inter(self.dense_AdjMat)[0]\n",
        "    #self.inter_matrix = J_inter(self.dense_AdjMat)[1]\n",
        "    self._episode_ended = False\n",
        "    return ts.restart(np.array(self._state, dtype=np.int32))\n",
        "\n",
        "  def _step(self, action):\n",
        "    if self._episode_ended:\n",
        "      return self.reset()\n",
        "\n",
        "    if self.__all_spins_down():\n",
        "      self._episode_ended = True\n",
        "    elif (action>=0 and action<=self.N-1) and (self._state[action,0]==1):\n",
        "      self._state[action,0]=-1\n",
        "      rew = self.computeReward(action)\n",
        "\n",
        "      if self.__all_spins_down():\n",
        "          self._episode_ended = True\n",
        "          return ts.termination(np.array(self._state, dtype=np.int32), reward=rew)\n",
        "      else:\n",
        "          return ts.transition(np.array(self._state, dtype=np.int32), reward=rew)\n",
        "\n",
        "    elif (action>=0 and action<=self.N-1) and (self._state[action,0]==-1):\n",
        "      return ts.transition(np.array(self._state, dtype=np.int32), reward=0)\n",
        "    else:\n",
        "      raise ValueError('`action` should be 0 up to N-1 - Spin Flip!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "9b286d1ecbac40afa11a0583b4efa360",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "93JAVDpOD6E6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "ac958be7258d468bac98c788f6411489",
        "source_hash": "7ced6c7",
        "execution_start": 1654006797406,
        "execution_millis": 1,
        "deepnote_cell_height": 351,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "YAd-_UjVD6E7"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, N_graph, X, Y, A, E, **kwargs):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.N_graph = N_graph\n",
        "        self.A = A\n",
        "        self.E = E\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def read(self):\n",
        "        mydataset = []\n",
        "        for i in range(self.N_graph):\n",
        "            mydataset.append(\n",
        "                    Graph(x=self.X[i], a=self.A[i], e=self.E[i], y=self.Y[i])\n",
        "                    )\n",
        "        return mydataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "2df8e810ffbd430ab9137a7751d53d54",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "f0hY3VnoD6E7"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "f7257f6b0c0a48e2b9505dd5bbc93189",
        "source_hash": "cc1b0ee6",
        "execution_start": 1654006797509,
        "execution_millis": 202155,
        "deepnote_cell_height": 639,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "WKPaOoRtD6E8"
      },
      "source": [
        "def agent(N,         # number nodes\n",
        "          D,         # number dimensions\n",
        "          stack_channels=5,\n",
        "          node_channels=3,\n",
        "          edge_channels=3,\n",
        "          division_factor_dense=4,\n",
        "          p_drop=0,\n",
        "          N_xenet=2,\n",
        "          N_dense=2,\n",
        "          activation=\"relu\",\n",
        "          regularizer=0):\n",
        "  inX = Input(shape=(N,1), name='Input Nodes')\n",
        "  inA = Input(shape=(N,N), name='Input Adj matrix')\n",
        "  inE = Input(shape=(N,N,1), name='Input Edges')\n",
        "\n",
        "  XENet_layer = XENetDenseConv(stack_channels, node_channels, edge_channels,\n",
        "                     attention=True, node_activation=activation, edge_activation=activation, kernel_regularizer=l2(regularizer), name=\"XENet_layer\")\n",
        "  X, E = XENet_layer([inX, inA, inE])\n",
        "  for i in range(N_xenet-1):\n",
        "    X, E = XENet_layer([X, inA, E])\n",
        "\n",
        "  flat_x, flat_e = Flatten(name=\"Nodes_encoding\")(X), Flatten(name=\"Edges_encoding\")(E)\n",
        "  out = Concatenate(axis=1, name=\"Concatenation\")([flat_x,flat_e])\n",
        "\n",
        "  for i in range(N_dense):\n",
        "    out = Dense(out.shape.as_list()[1]//division_factor_dense, activation=activation, kernel_regularizer=l2(regularizer))(out)\n",
        "    out = Dropout(p_drop)(out)\n",
        "  out = Dense(N, activation=\"PReLU\", kernel_regularizer=l2(regularizer), name='Q-values')(out)\n",
        "\n",
        "  model = Model([inX,inA,inE], out)\n",
        "  model.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "6aa613cb416041b59a636a8bbc0b9f99",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "ykNW1EHcD6E8"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "788e2eaf0cf2459dbb940e1963efa05a",
        "source_hash": "cfd1cf56",
        "execution_start": 1654006797510,
        "execution_millis": 202119,
        "deepnote_cell_height": 945,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "cE6GPT0VD6E8"
      },
      "source": [
        "def train(env, replay_memory, model, target_model, done, MIN_REPLAY_SIZE, batch_size):\n",
        "    #learning_rate = 0.7                                         # Learning rate\n",
        "    discount_factor = 0.618\n",
        "\n",
        "    MIN_REPLAY_SIZE = MIN_REPLAY_SIZE\n",
        "    print(\"\\t=> replay_memory size:\", len(replay_memory))\n",
        "    if len(replay_memory) < MIN_REPLAY_SIZE:\n",
        "        print(\"\\t=> EXIT\\n\")\n",
        "        return\n",
        "\n",
        "    batch_size = batch_size\n",
        "    mini_batch = random.sample(replay_memory, batch_size)\n",
        "\n",
        "    E = np.array([transition[-1] for transition in mini_batch])\n",
        "    A = np.array([transition[-2] for transition in mini_batch])\n",
        "    current_states = np.array([transition[0] for transition in mini_batch])\n",
        "    #current_qs_list = np.array([model.predict([current_states[new_current_states[i],A[i],E[i]])[0] for i in range(batch_size)])\n",
        "    current_qs_list = np.array(model.predict([current_states,A,E]))\n",
        "    #current_qs_list = model.predict(current_states[1])[0]\n",
        "\n",
        "    new_current_states = np.array([transition[3] for transition in mini_batch])\n",
        "    #future_qs_list = np.array([target_model.predict(new_current_states[i],A[i],E[i])[0] for i in range(batch_size)])\n",
        "    future_qs_list = np.array(target_model.predict([new_current_states,A,E]))\n",
        "    #future_qs_list = target_model.predict(new_current_states).numpy()[0]\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    for index, (observation, action, reward, new_observation, done, dense_AdjMat, inter_matrix) in enumerate(mini_batch):\n",
        "        if not done:\n",
        "            max_future_q = reward + discount_factor*np.max(future_qs_list[index])\n",
        "            #max_future_q = sum of reward + discount_factor * np.max(future_qs_list[index])\n",
        "        else:\n",
        "            max_future_q = reward\n",
        "\n",
        "        current_qs = current_qs_list[index]\n",
        "        current_qs[action] = max_future_q\n",
        "\n",
        "\n",
        "        X.append(observation)\n",
        "        Y.append(current_qs)\n",
        "    #print(\"\\tX: \", np.array(X).shape, \"\\n\", X)\n",
        "    #print(\"\\tY: \",np.array(Y).shape, \"\\n\", Y)\n",
        "\n",
        "\n",
        "    train_data = MyDataset(N_graph=batch_size, X=X, Y=Y, A=A, E=E)\n",
        "    loader = BatchLoader(train_data, node_level=False, epochs=50, batch_size=batch_size, shuffle=False)\n",
        "    model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, verbose=2,\n",
        "              callbacks = [WandbCallback()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "48914c46ecf24b36ab31e848e6bedecb",
        "source_hash": "906d3814",
        "execution_start": 1654006797512,
        "execution_millis": 202118,
        "deepnote_cell_height": 333,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "lNxtc_6CD6E9"
      },
      "source": [
        "def get_replay_memory(trajectory_buffer, replay_memory):\n",
        "    n = len(trajectory_buffer)\n",
        "\n",
        "    states = np.array([transition[0] for transition in trajectory_buffer])\n",
        "    actions = np.array([transition[1] for transition in trajectory_buffer])\n",
        "    rewards = np.array([transition[2] for transition in trajectory_buffer])\n",
        "    done = np.array([transition[4] for transition in trajectory_buffer])\n",
        "    inter_matrix = trajectory_buffer[0][-1]\n",
        "    dense_AdjMat = trajectory_buffer[0][-2]\n",
        "\n",
        "    cum_reward = np.cumsum(rewards)\n",
        "\n",
        "    replay_memory.append([states[0], actions[0], cum_reward[n-1], states[n-1], done[n-1], dense_AdjMat, inter_matrix])\n",
        "\n",
        "    return replay_memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "cell_id": "6818308739b24ceeafea88e987819bcb",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "sVwIKWaeD6E9"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "7bc9e340aece4c73a05d6a0340eb45e0",
        "source_hash": "cf40dfdb",
        "execution_start": 1654007318448,
        "execution_millis": 5,
        "deepnote_cell_height": 549,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "eLh_N3HLD6E9"
      },
      "source": [
        "def test(env, model):\n",
        "\n",
        "    env.reset()\n",
        "    energy = []\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "\n",
        "        observation = env.get_state()\n",
        "\n",
        "        # Exploit best known action\n",
        "        predicted = model([observation.reshape(1,env.N,1), env.dense_AdjMat.reshape(1,env.N,env.N), env.inter_matrix.reshape(1,env.N,env.N,1)], training=False).numpy()[0]\n",
        "        while True:\n",
        "            #check to prevent flipping the same spin twice - only once!\n",
        "            action = np.argmax(predicted)\n",
        "            if env.get_state()[action,0] == 1:\n",
        "                    break;\n",
        "            predicted[action] = np.NINF\n",
        "\n",
        "        step_type, reward, discount, new_observation = env._step(action)\n",
        "        done = env._episode_ended\n",
        "        e = env.computeEnergy()\n",
        "        energy.append([new_observation, e])\n",
        "\n",
        "        ground_state = energy[energy[1]==min(energy[1])]\n",
        "        print(\"Ground state: \", ground_state)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "7a360107aa144d4fa4297a373b4946c8",
        "source_hash": "62dbb5dc",
        "owner_user_id": "d8aa7146-c8e6-479e-9e49-136a058e4f85",
        "execution_start": 1654007383356,
        "execution_millis": 0,
        "deepnote_cell_height": 2169,
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "TRKzbjnFD6E-"
      },
      "source": [
        "def main(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        L = 3\n",
        "        D = 2\n",
        "        env = SG_env(L=L, D=D)\n",
        "        #env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "        epsilon = 1          # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\n",
        "        max_epsilon = 1      # You can't explore more than 100% of the time\n",
        "        min_epsilon = 0.01   # At a minimum, we'll always explore 1% of the time\n",
        "        decay = 0.01\n",
        "\n",
        "        # 1. Initialize the Target and Main models\n",
        "        # Main Model (updated every 4 steps)\n",
        "        model = agent(N=env.N, D=D, stack_channels=config.stack_channels,\n",
        "                node_channels=config.node_channels, edge_channels=config.edge_channels,\n",
        "                N_xenet=config.N_xenet, N_dense=config.N_dense,\n",
        "                division_factor_dense=config.division_factor_dense)\n",
        "\n",
        "        # Target Model (updated at the end of every episode)\n",
        "        target_model = agent(N=env.N, D=D, stack_channels=config.stack_channels,\n",
        "                node_channels=config.node_channels, edge_channels=config.edge_channels,\n",
        "                N_xenet=config.N_xenet, N_dense=config.N_dense,\n",
        "                division_factor_dense=config.division_factor_dense)\n",
        "        target_model.set_weights(model.get_weights())\n",
        "\n",
        "        energy_buffer = []\n",
        "        replay_memory = []\n",
        "\n",
        "        train_episodes = config.train_episodes\n",
        "        for episode in range(train_episodes):\n",
        "            trajectory_buffer = []\n",
        "            total_training_rewards = 0\n",
        "            steps_to_update_target_model = 0\n",
        "            env.reset()\n",
        "            previous_obs = np.ones(shape=(env.N,1)).astype(\"int32\")\n",
        "            done = False\n",
        "            check = np.arange(0,env.N)\n",
        "\n",
        "            while not done:\n",
        "                observation = env.get_state()\n",
        "                print(\"\\n\\t\\t\\t\\t++++++++++++  episode:\", episode,\" - step:\", steps_to_update_target_model, \" ++++++++++++\")\n",
        "                #print(\"len(trajectory_buffer):\", len(trajectory_buffer))\n",
        "                #print(\"len(replay_memory):\", len(replay_memory))\n",
        "\n",
        "                # 2. Explore using the Epsilon Greedy Exploration Strategy\n",
        "                random_number = np.random.rand()\n",
        "                if random_number <= epsilon:\n",
        "                    # Explore\n",
        "                    action = random.choice(check)\n",
        "\n",
        "                else:\n",
        "                    # Exploit best known action\n",
        "                    predicted = model([observation.reshape(1,env.N,1), env.dense_AdjMat.reshape(1,env.N,env.N), env.inter_matrix.reshape(1,env.N,env.N,1)], training=False).numpy()[0]\n",
        "                    while True:\n",
        "                        #check to prevent flipping the same spin twice - only once!\n",
        "                        action = np.argmax(predicted)\n",
        "                        if env.get_state()[action,0] == 1:\n",
        "                                break;\n",
        "                        predicted[action] = np.NINF\n",
        "\n",
        "                check = np.setdiff1d(check, action)\n",
        "                step_type, reward, discount, new_observation = env._step(action)\n",
        "                done = env._episode_ended\n",
        "                e = env.computeEnergy()\n",
        "                trajectory_buffer.append([previous_obs, action, reward, new_observation, done, e, env.dense_AdjMat, env.inter_matrix])\n",
        "                energy_buffer.append([episode, new_observation, env.interaction, e])\n",
        "\n",
        "                wandb.log({\n",
        "                    \"Episode\": energy_buffer[episode*env.N+steps_to_update_target_model][0],\n",
        "                    \"Step\": episode*env.N+steps_to_update_target_model,\n",
        "                    \"New observation\": wandb.Image(energy_buffer[episode*env.N+steps_to_update_target_model][1].reshape(L,L)),\n",
        "                    \"J interactions\": energy_buffer[episode*env.N+steps_to_update_target_model][2],\n",
        "                    \"Energy\": energy_buffer[episode*env.N+steps_to_update_target_model][3]\n",
        "                })\n",
        "                #print(\"=> observation\",previous_obs)\n",
        "                #print(\"=> new observation\",new_observation)\n",
        "                #print(\"=> action:\",action)\n",
        "                #print(\"=> reward:\",reward)\n",
        "                #print(\"=> done:\",done)\n",
        "                #print(\"=> e:\",e)\n",
        "                #print(\"=> trajectory_buffer:\", trajectory_buffer)\n",
        "\n",
        "                if steps_to_update_target_model >= config.step_buffer:\n",
        "                    replay_memory = get_replay_memory(trajectory_buffer, replay_memory)\n",
        "                    #print(\"=> replay_memory:\", replay_memory, \"\\n\")\n",
        "                    trajectory_buffer = trajectory_buffer[1:]\n",
        "                    #print(\"=> trajectory_buffer:\", trajectory_buffer)\n",
        "\n",
        "\n",
        "                # 3. Update the Main Network using the Bellman Equation\n",
        "                #if (steps_to_update_target_model%L==0 and steps_to_update_target_model!=0) or done:\n",
        "                    #replay_memory = get_replay_memory(trajectory_buffer)\n",
        "                print(\"\\n\\t\\t\\t\\t\\t      +++++ Training +++++\")\n",
        "                train(env, replay_memory, model, target_model, done, config.MIN_REPLAY_SIZE, config.batch_size)\n",
        "\n",
        "\n",
        "                previous_obs = new_observation\n",
        "                total_training_rewards += reward\n",
        "\n",
        "                #print(\"=> total_training_rewards:\", total_training_rewards, \"\\n\")\n",
        "\n",
        "                if done:\n",
        "                    if episode >= 3:\n",
        "                        #Copying main network weights to the target network weights\n",
        "                        target_model.set_weights(model.get_weights())\n",
        "\n",
        "                steps_to_update_target_model += 1\n",
        "\n",
        "            epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
        "        #env.close()\n",
        "\n",
        "        #test(env, model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "5a15f74eecac43c1bfcb92b07b39ef22",
        "source_hash": "fbe79b7f",
        "execution_start": 1654006797687,
        "execution_millis": 327632,
        "deepnote_cell_height": 1210.5625,
        "deepnote_output_heights": [
          null,
          21.1875,
          22.1875,
          40.375
        ],
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "WttZuIxSD6E-",
        "outputId": "4796fc63-2a9d-4474-c630-f0db878d8f26"
      },
      "source": [
        "wandb.agent(sweep_id, main, count=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k6sdeps0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tMIN_REPLAY_SIZE: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tN_dense: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tN_xenet: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdivision_factor_dense: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tedge_channels: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnode_channels: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tstack_channels: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tstep_buffer: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_episodes: 100\nFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfilippo_festa\u001b[0m (\u001b[33mlocp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n/shared-libs/python3.7/py-core/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.12.17"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/work/wandb/run-20220531_141958-k6sdeps0</code>"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href=\"https://wandb.ai/locp/randomSearch-project/runs/k6sdeps0\" target=\"_blank\">flowing-sweep-1</a></strong> to <a href=\"https://wandb.ai/locp/randomSearch-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/locp/randomSearch-project/sweeps/ws8ob6ro\" target=\"_blank\">https://wandb.ai/locp/randomSearch-project/sweeps/ws8ob6ro</a>"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "text": "\n\t\t\t\t++++++++++++  episode: 61  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 366\n1/1 - 0s - loss: 1.9647 - _timestamp: 1654007045.0000 - _runtime: 247.0000 - 164ms/epoch - 164ms/step\n\n\t\t\t\t++++++++++++  episode: 61  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 367\n1/1 - 0s - loss: 1.9174 - _timestamp: 1654007046.0000 - _runtime: 248.0000 - 174ms/epoch - 174ms/step\n\n\t\t\t\t++++++++++++  episode: 61  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 368\n1/1 - 0s - loss: 2.4596 - _timestamp: 1654007046.0000 - _runtime: 248.0000 - 155ms/epoch - 155ms/step\n\n\t\t\t\t++++++++++++  episode: 61  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 369\n1/1 - 0s - loss: 2.0558 - _timestamp: 1654007047.0000 - _runtime: 249.0000 - 121ms/epoch - 121ms/step\n\n\t\t\t\t++++++++++++  episode: 61  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 370\n1/1 - 0s - loss: 0.9417 - _timestamp: 1654007047.0000 - _runtime: 249.0000 - 114ms/epoch - 114ms/step\n\n\t\t\t\t++++++++++++  episode: 61  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 371\n1/1 - 0s - loss: 1.3156 - _timestamp: 1654007048.0000 - _runtime: 250.0000 - 125ms/epoch - 125ms/step\n\n\t\t\t\t++++++++++++  episode: 61  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 372\n1/1 - 0s - loss: 1.9375 - _timestamp: 1654007048.0000 - _runtime: 250.0000 - 163ms/epoch - 163ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 372\n1/1 - 0s - loss: 2.6332 - _timestamp: 1654007049.0000 - _runtime: 251.0000 - 162ms/epoch - 162ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 372\n1/1 - 0s - loss: 1.9963 - _timestamp: 1654007049.0000 - _runtime: 251.0000 - 161ms/epoch - 161ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 372\n1/1 - 0s - loss: 1.2373 - _timestamp: 1654007050.0000 - _runtime: 252.0000 - 112ms/epoch - 112ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 373\n1/1 - 0s - loss: 1.5873 - _timestamp: 1654007050.0000 - _runtime: 252.0000 - 113ms/epoch - 113ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 374\n1/1 - 0s - loss: 0.5497 - _timestamp: 1654007051.0000 - _runtime: 253.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 375\n1/1 - 0s - loss: 1.1485 - _timestamp: 1654007051.0000 - _runtime: 253.0000 - 171ms/epoch - 171ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 376\n1/1 - 0s - loss: 2.3020 - _timestamp: 1654007052.0000 - _runtime: 254.0000 - 159ms/epoch - 159ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 377\n1/1 - 0s - loss: 0.8131 - _timestamp: 1654007052.0000 - _runtime: 254.0000 - 172ms/epoch - 172ms/step\n\n\t\t\t\t++++++++++++  episode: 62  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 378\n1/1 - 0s - loss: 1.3482 - _timestamp: 1654007053.0000 - _runtime: 255.0000 - 119ms/epoch - 119ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 378\n1/1 - 0s - loss: 1.1892 - _timestamp: 1654007053.0000 - _runtime: 255.0000 - 123ms/epoch - 123ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 378\n1/1 - 0s - loss: 1.8159 - _timestamp: 1654007054.0000 - _runtime: 256.0000 - 183ms/epoch - 183ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 378\n1/1 - 0s - loss: 1.5954 - _timestamp: 1654007054.0000 - _runtime: 256.0000 - 113ms/epoch - 113ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 379\n1/1 - 0s - loss: 1.1652 - _timestamp: 1654007055.0000 - _runtime: 257.0000 - 175ms/epoch - 175ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 380\n1/1 - 0s - loss: 1.4151 - _timestamp: 1654007055.0000 - _runtime: 257.0000 - 121ms/epoch - 121ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 381\n1/1 - 0s - loss: 0.9660 - _timestamp: 1654007055.0000 - _runtime: 257.0000 - 173ms/epoch - 173ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 382\n1/1 - 0s - loss: 1.7277 - _timestamp: 1654007056.0000 - _runtime: 258.0000 - 185ms/epoch - 185ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 383\n1/1 - 0s - loss: 1.3311 - _timestamp: 1654007056.0000 - _runtime: 258.0000 - 113ms/epoch - 113ms/step\n\n\t\t\t\t++++++++++++  episode: 63  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 384\n1/1 - 0s - loss: 1.0976 - _timestamp: 1654007057.0000 - _runtime: 259.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 384\n1/1 - 0s - loss: 0.9912 - _timestamp: 1654007058.0000 - _runtime: 260.0000 - 108ms/epoch - 108ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 384\n1/1 - 0s - loss: 3.1321 - _timestamp: 1654007058.0000 - _runtime: 260.0000 - 113ms/epoch - 113ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 384\n1/1 - 0s - loss: 2.6577 - _timestamp: 1654007058.0000 - _runtime: 260.0000 - 109ms/epoch - 109ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 385\n1/1 - 0s - loss: 1.5606 - _timestamp: 1654007059.0000 - _runtime: 261.0000 - 161ms/epoch - 161ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 386\n1/1 - 0s - loss: 0.5940 - _timestamp: 1654007059.0000 - _runtime: 261.0000 - 168ms/epoch - 168ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 387\n1/1 - 0s - loss: 1.6036 - _timestamp: 1654007060.0000 - _runtime: 262.0000 - 172ms/epoch - 172ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 388\n1/1 - 0s - loss: 0.9899 - _timestamp: 1654007060.0000 - _runtime: 262.0000 - 172ms/epoch - 172ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 389\n1/1 - 0s - loss: 0.7318 - _timestamp: 1654007061.0000 - _runtime: 263.0000 - 103ms/epoch - 103ms/step\n\n\t\t\t\t++++++++++++  episode: 64  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 390\n1/1 - 0s - loss: 1.0197 - _timestamp: 1654007061.0000 - _runtime: 263.0000 - 167ms/epoch - 167ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 390\n1/1 - 0s - loss: 2.0505 - _timestamp: 1654007062.0000 - _runtime: 264.0000 - 157ms/epoch - 157ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 390\n1/1 - 0s - loss: 1.4121 - _timestamp: 1654007062.0000 - _runtime: 264.0000 - 113ms/epoch - 113ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 390\n1/1 - 0s - loss: 2.2219 - _timestamp: 1654007063.0000 - _runtime: 265.0000 - 160ms/epoch - 160ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 391\n1/1 - 0s - loss: 1.8029 - _timestamp: 1654007063.0000 - _runtime: 265.0000 - 109ms/epoch - 109ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 392\n1/1 - 0s - loss: 1.2372 - _timestamp: 1654007064.0000 - _runtime: 266.0000 - 175ms/epoch - 175ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 393\n1/1 - 0s - loss: 0.9064 - _timestamp: 1654007064.0000 - _runtime: 266.0000 - 112ms/epoch - 112ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 394\n1/1 - 0s - loss: 0.7775 - _timestamp: 1654007065.0000 - _runtime: 267.0000 - 152ms/epoch - 152ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 395\n1/1 - 0s - loss: 1.0016 - _timestamp: 1654007065.0000 - _runtime: 267.0000 - 172ms/epoch - 172ms/step\n\n\t\t\t\t++++++++++++  episode: 65  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 396\n1/1 - 0s - loss: 1.3705 - _timestamp: 1654007066.0000 - _runtime: 268.0000 - 98ms/epoch - 98ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 396\n1/1 - 0s - loss: 0.8357 - _timestamp: 1654007067.0000 - _runtime: 269.0000 - 108ms/epoch - 108ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 396\n1/1 - 0s - loss: 1.1352 - _timestamp: 1654007067.0000 - _runtime: 269.0000 - 120ms/epoch - 120ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 396\n1/1 - 0s - loss: 1.3500 - _timestamp: 1654007068.0000 - _runtime: 270.0000 - 122ms/epoch - 122ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 397\n1/1 - 0s - loss: 2.3655 - _timestamp: 1654007068.0000 - _runtime: 270.0000 - 156ms/epoch - 156ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 398\n1/1 - 0s - loss: 0.8344 - _timestamp: 1654007068.0000 - _runtime: 270.0000 - 118ms/epoch - 118ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 399\n1/1 - 0s - loss: 0.8591 - _timestamp: 1654007069.0000 - _runtime: 271.0000 - 161ms/epoch - 161ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 400\n1/1 - 0s - loss: 1.6253 - _timestamp: 1654007069.0000 - _runtime: 271.0000 - 157ms/epoch - 157ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 401\n1/1 - 0s - loss: 1.0519 - _timestamp: 1654007070.0000 - _runtime: 272.0000 - 163ms/epoch - 163ms/step\n\n\t\t\t\t++++++++++++  episode: 66  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 402\n1/1 - 0s - loss: 0.9663 - _timestamp: 1654007070.0000 - _runtime: 272.0000 - 107ms/epoch - 107ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 402\n1/1 - 0s - loss: 3.1568 - _timestamp: 1654007071.0000 - _runtime: 273.0000 - 154ms/epoch - 154ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 402\n1/1 - 0s - loss: 1.2661 - _timestamp: 1654007071.0000 - _runtime: 273.0000 - 101ms/epoch - 101ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 402\n1/1 - 0s - loss: 1.0289 - _timestamp: 1654007072.0000 - _runtime: 274.0000 - 115ms/epoch - 115ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 403\n1/1 - 0s - loss: 0.7370 - _timestamp: 1654007072.0000 - _runtime: 274.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 404\n1/1 - 0s - loss: 0.9724 - _timestamp: 1654007073.0000 - _runtime: 275.0000 - 157ms/epoch - 157ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 405\n1/1 - 0s - loss: 1.8723 - _timestamp: 1654007073.0000 - _runtime: 275.0000 - 171ms/epoch - 171ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 406\n1/1 - 0s - loss: 0.9604 - _timestamp: 1654007074.0000 - _runtime: 276.0000 - 161ms/epoch - 161ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 407\n1/1 - 0s - loss: 1.4937 - _timestamp: 1654007074.0000 - _runtime: 276.0000 - 163ms/epoch - 163ms/step\n\n\t\t\t\t++++++++++++  episode: 67  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 408\n1/1 - 0s - loss: 0.9945 - _timestamp: 1654007075.0000 - _runtime: 277.0000 - 158ms/epoch - 158ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 408\n1/1 - 0s - loss: 1.3762 - _timestamp: 1654007075.0000 - _runtime: 277.0000 - 167ms/epoch - 167ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 408\n1/1 - 0s - loss: 1.1637 - _timestamp: 1654007076.0000 - _runtime: 278.0000 - 111ms/epoch - 111ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 408\n1/1 - 0s - loss: 1.8085 - _timestamp: 1654007076.0000 - _runtime: 278.0000 - 174ms/epoch - 174ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 409\n1/1 - 0s - loss: 1.1552 - _timestamp: 1654007077.0000 - _runtime: 279.0000 - 153ms/epoch - 153ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 410\n1/1 - 0s - loss: 1.2474 - _timestamp: 1654007077.0000 - _runtime: 279.0000 - 105ms/epoch - 105ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 411\n1/1 - 0s - loss: 0.9423 - _timestamp: 1654007078.0000 - _runtime: 280.0000 - 120ms/epoch - 120ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 412\n1/1 - 0s - loss: 1.4000 - _timestamp: 1654007078.0000 - _runtime: 280.0000 - 182ms/epoch - 182ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 413\n1/1 - 0s - loss: 0.8720 - _timestamp: 1654007079.0000 - _runtime: 281.0000 - 121ms/epoch - 121ms/step\n\n\t\t\t\t++++++++++++  episode: 68  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 414\n1/1 - 0s - loss: 1.7648 - _timestamp: 1654007079.0000 - _runtime: 281.0000 - 128ms/epoch - 128ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 414\n1/1 - 0s - loss: 0.7848 - _timestamp: 1654007080.0000 - _runtime: 282.0000 - 125ms/epoch - 125ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 414\n1/1 - 0s - loss: 0.7709 - _timestamp: 1654007080.0000 - _runtime: 282.0000 - 174ms/epoch - 174ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 414\n1/1 - 0s - loss: 0.8809 - _timestamp: 1654007081.0000 - _runtime: 283.0000 - 165ms/epoch - 165ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 415\n1/1 - 0s - loss: 0.7610 - _timestamp: 1654007081.0000 - _runtime: 283.0000 - 184ms/epoch - 184ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 416\n1/1 - 0s - loss: 1.4332 - _timestamp: 1654007081.0000 - _runtime: 283.0000 - 152ms/epoch - 152ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 417\n1/1 - 0s - loss: 0.9634 - _timestamp: 1654007082.0000 - _runtime: 284.0000 - 118ms/epoch - 118ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 418\n1/1 - 0s - loss: 1.1596 - _timestamp: 1654007082.0000 - _runtime: 284.0000 - 155ms/epoch - 155ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 419\n1/1 - 0s - loss: 2.2819 - _timestamp: 1654007083.0000 - _runtime: 285.0000 - 162ms/epoch - 162ms/step\n\n\t\t\t\t++++++++++++  episode: 69  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 420\n1/1 - 0s - loss: 1.8254 - _timestamp: 1654007083.0000 - _runtime: 285.0000 - 168ms/epoch - 168ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 420\n1/1 - 0s - loss: 0.7808 - _timestamp: 1654007084.0000 - _runtime: 286.0000 - 161ms/epoch - 161ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 420\n1/1 - 0s - loss: 1.6130 - _timestamp: 1654007084.0000 - _runtime: 286.0000 - 118ms/epoch - 118ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 420\n1/1 - 0s - loss: 1.7250 - _timestamp: 1654007085.0000 - _runtime: 287.0000 - 168ms/epoch - 168ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 421\n1/1 - 0s - loss: 1.1582 - _timestamp: 1654007085.0000 - _runtime: 287.0000 - 123ms/epoch - 123ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 422\n1/1 - 0s - loss: 1.3252 - _timestamp: 1654007086.0000 - _runtime: 288.0000 - 152ms/epoch - 152ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 423\n1/1 - 0s - loss: 1.4605 - _timestamp: 1654007086.0000 - _runtime: 288.0000 - 164ms/epoch - 164ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 424\n1/1 - 0s - loss: 1.2500 - _timestamp: 1654007087.0000 - _runtime: 289.0000 - 122ms/epoch - 122ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 425\n1/1 - 0s - loss: 1.1158 - _timestamp: 1654007087.0000 - _runtime: 289.0000 - 105ms/epoch - 105ms/step\n\n\t\t\t\t++++++++++++  episode: 70  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 426\n1/1 - 0s - loss: 1.2043 - _timestamp: 1654007088.0000 - _runtime: 290.0000 - 162ms/epoch - 162ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 426\n1/1 - 0s - loss: 1.6893 - _timestamp: 1654007088.0000 - _runtime: 290.0000 - 158ms/epoch - 158ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 426\n1/1 - 0s - loss: 1.3877 - _timestamp: 1654007089.0000 - _runtime: 291.0000 - 170ms/epoch - 170ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 426\n1/1 - 0s - loss: 1.4790 - _timestamp: 1654007089.0000 - _runtime: 291.0000 - 164ms/epoch - 164ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 427\n1/1 - 0s - loss: 0.8758 - _timestamp: 1654007090.0000 - _runtime: 292.0000 - 165ms/epoch - 165ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 428\n1/1 - 0s - loss: 0.9708 - _timestamp: 1654007090.0000 - _runtime: 292.0000 - 160ms/epoch - 160ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 429\n1/1 - 0s - loss: 0.8361 - _timestamp: 1654007091.0000 - _runtime: 293.0000 - 123ms/epoch - 123ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 430\n1/1 - 0s - loss: 1.6633 - _timestamp: 1654007091.0000 - _runtime: 293.0000 - 121ms/epoch - 121ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 431\n1/1 - 0s - loss: 1.5114 - _timestamp: 1654007092.0000 - _runtime: 294.0000 - 156ms/epoch - 156ms/step\n\n\t\t\t\t++++++++++++  episode: 71  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 432\n1/1 - 0s - loss: 1.2607 - _timestamp: 1654007092.0000 - _runtime: 294.0000 - 116ms/epoch - 116ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 432\n1/1 - 0s - loss: 1.7076 - _timestamp: 1654007092.0000 - _runtime: 294.0000 - 171ms/epoch - 171ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 432\n1/1 - 0s - loss: 0.7874 - _timestamp: 1654007093.0000 - _runtime: 295.0000 - 164ms/epoch - 164ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 432\n1/1 - 0s - loss: 0.9253 - _timestamp: 1654007093.0000 - _runtime: 295.0000 - 118ms/epoch - 118ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 433\n1/1 - 0s - loss: 1.7724 - _timestamp: 1654007094.0000 - _runtime: 296.0000 - 111ms/epoch - 111ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 434\n1/1 - 0s - loss: 2.1044 - _timestamp: 1654007094.0000 - _runtime: 296.0000 - 116ms/epoch - 116ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 435\n1/1 - 0s - loss: 0.8441 - _timestamp: 1654007095.0000 - _runtime: 297.0000 - 165ms/epoch - 165ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 436\n1/1 - 0s - loss: 1.7110 - _timestamp: 1654007095.0000 - _runtime: 297.0000 - 173ms/epoch - 173ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 437\n1/1 - 0s - loss: 1.5094 - _timestamp: 1654007096.0000 - _runtime: 298.0000 - 119ms/epoch - 119ms/step\n\n\t\t\t\t++++++++++++  episode: 72  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 438\n1/1 - 0s - loss: 2.2382 - _timestamp: 1654007096.0000 - _runtime: 298.0000 - 130ms/epoch - 130ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 438\n1/1 - 0s - loss: 1.7679 - _timestamp: 1654007097.0000 - _runtime: 299.0000 - 108ms/epoch - 108ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 438\n1/1 - 0s - loss: 2.1642 - _timestamp: 1654007097.0000 - _runtime: 299.0000 - 114ms/epoch - 114ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 438\n1/1 - 0s - loss: 1.7084 - _timestamp: 1654007098.0000 - _runtime: 300.0000 - 168ms/epoch - 168ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 439\n1/1 - 0s - loss: 1.3729 - _timestamp: 1654007098.0000 - _runtime: 300.0000 - 157ms/epoch - 157ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 440\n1/1 - 0s - loss: 1.3603 - _timestamp: 1654007099.0000 - _runtime: 301.0000 - 165ms/epoch - 165ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 441\n1/1 - 0s - loss: 0.7884 - _timestamp: 1654007099.0000 - _runtime: 301.0000 - 179ms/epoch - 179ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 442\n1/1 - 0s - loss: 1.1053 - _timestamp: 1654007100.0000 - _runtime: 302.0000 - 170ms/epoch - 170ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 443\n1/1 - 0s - loss: 1.4016 - _timestamp: 1654007100.0000 - _runtime: 302.0000 - 169ms/epoch - 169ms/step\n\n\t\t\t\t++++++++++++  episode: 73  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 444\n1/1 - 0s - loss: 1.5196 - _timestamp: 1654007100.0000 - _runtime: 302.0000 - 95ms/epoch - 95ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 444\n1/1 - 0s - loss: 2.0506 - _timestamp: 1654007101.0000 - _runtime: 303.0000 - 114ms/epoch - 114ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 444\n1/1 - 0s - loss: 0.9358 - _timestamp: 1654007101.0000 - _runtime: 303.0000 - 158ms/epoch - 158ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 444\n1/1 - 0s - loss: 2.0148 - _timestamp: 1654007102.0000 - _runtime: 304.0000 - 161ms/epoch - 161ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 445\n1/1 - 0s - loss: 0.5696 - _timestamp: 1654007102.0000 - _runtime: 304.0000 - 115ms/epoch - 115ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 446\n1/1 - 0s - loss: 1.2462 - _timestamp: 1654007103.0000 - _runtime: 305.0000 - 149ms/epoch - 149ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 447\n1/1 - 0s - loss: 0.6676 - _timestamp: 1654007103.0000 - _runtime: 305.0000 - 98ms/epoch - 98ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 448\n1/1 - 0s - loss: 1.2639 - _timestamp: 1654007103.0000 - _runtime: 305.0000 - 147ms/epoch - 147ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 449\n1/1 - 0s - loss: 2.0244 - _timestamp: 1654007104.0000 - _runtime: 306.0000 - 99ms/epoch - 99ms/step\n\n\t\t\t\t++++++++++++  episode: 74  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 450\n1/1 - 0s - loss: 0.6089 - _timestamp: 1654007104.0000 - _runtime: 306.0000 - 152ms/epoch - 152ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 450\n1/1 - 0s - loss: 2.1394 - _timestamp: 1654007104.0000 - _runtime: 306.0000 - 153ms/epoch - 153ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 450\n1/1 - 0s - loss: 0.6908 - _timestamp: 1654007105.0000 - _runtime: 307.0000 - 157ms/epoch - 157ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 450\n1/1 - 0s - loss: 1.9663 - _timestamp: 1654007105.0000 - _runtime: 307.0000 - 156ms/epoch - 156ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 451\n1/1 - 0s - loss: 1.1597 - _timestamp: 1654007106.0000 - _runtime: 308.0000 - 109ms/epoch - 109ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 452\n1/1 - 0s - loss: 0.9668 - _timestamp: 1654007106.0000 - _runtime: 308.0000 - 154ms/epoch - 154ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 453\n1/1 - 0s - loss: 1.1272 - _timestamp: 1654007107.0000 - _runtime: 309.0000 - 184ms/epoch - 184ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 454\n1/1 - 0s - loss: 1.4120 - _timestamp: 1654007107.0000 - _runtime: 309.0000 - 182ms/epoch - 182ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 455\n1/1 - 0s - loss: 1.2191 - _timestamp: 1654007108.0000 - _runtime: 310.0000 - 124ms/epoch - 124ms/step\n\n\t\t\t\t++++++++++++  episode: 75  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 456\n1/1 - 0s - loss: 2.1224 - _timestamp: 1654007108.0000 - _runtime: 310.0000 - 126ms/epoch - 126ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 456\n1/1 - 0s - loss: 1.1644 - _timestamp: 1654007109.0000 - _runtime: 311.0000 - 199ms/epoch - 199ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 456\n1/1 - 0s - loss: 1.8688 - _timestamp: 1654007109.0000 - _runtime: 311.0000 - 120ms/epoch - 120ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 456\n1/1 - 0s - loss: 0.8839 - _timestamp: 1654007110.0000 - _runtime: 312.0000 - 168ms/epoch - 168ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 457\n1/1 - 0s - loss: 1.2782 - _timestamp: 1654007110.0000 - _runtime: 312.0000 - 164ms/epoch - 164ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 458\n1/1 - 0s - loss: 0.8191 - _timestamp: 1654007111.0000 - _runtime: 313.0000 - 110ms/epoch - 110ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 459\n1/1 - 0s - loss: 1.4281 - _timestamp: 1654007111.0000 - _runtime: 313.0000 - 154ms/epoch - 154ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 460\n1/1 - 0s - loss: 1.2357 - _timestamp: 1654007112.0000 - _runtime: 314.0000 - 193ms/epoch - 193ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 461\n1/1 - 0s - loss: 1.3655 - _timestamp: 1654007112.0000 - _runtime: 314.0000 - 177ms/epoch - 177ms/step\n\n\t\t\t\t++++++++++++  episode: 76  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 462\n1/1 - 0s - loss: 0.8133 - _timestamp: 1654007113.0000 - _runtime: 315.0000 - 188ms/epoch - 188ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 462\n1/1 - 0s - loss: 1.5627 - _timestamp: 1654007113.0000 - _runtime: 315.0000 - 180ms/epoch - 180ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 462\n1/1 - 0s - loss: 1.5470 - _timestamp: 1654007114.0000 - _runtime: 316.0000 - 131ms/epoch - 131ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 462\n1/1 - 0s - loss: 1.2346 - _timestamp: 1654007114.0000 - _runtime: 316.0000 - 127ms/epoch - 127ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 463\n1/1 - 0s - loss: 1.7656 - _timestamp: 1654007115.0000 - _runtime: 317.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 464\n1/1 - 0s - loss: 1.4413 - _timestamp: 1654007115.0000 - _runtime: 317.0000 - 112ms/epoch - 112ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 465\n1/1 - 0s - loss: 1.8456 - _timestamp: 1654007116.0000 - _runtime: 318.0000 - 112ms/epoch - 112ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 466\n1/1 - 0s - loss: 1.3583 - _timestamp: 1654007116.0000 - _runtime: 318.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 467\n1/1 - 0s - loss: 1.4365 - _timestamp: 1654007117.0000 - _runtime: 319.0000 - 115ms/epoch - 115ms/step\n\n\t\t\t\t++++++++++++  episode: 77  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 468\n1/1 - 0s - loss: 1.6624 - _timestamp: 1654007117.0000 - _runtime: 319.0000 - 125ms/epoch - 125ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 468\n1/1 - 0s - loss: 0.7768 - _timestamp: 1654007118.0000 - _runtime: 320.0000 - 110ms/epoch - 110ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 468\n1/1 - 0s - loss: 1.6516 - _timestamp: 1654007119.0000 - _runtime: 321.0000 - 125ms/epoch - 125ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 468\n1/1 - 0s - loss: 1.1933 - _timestamp: 1654007119.0000 - _runtime: 321.0000 - 206ms/epoch - 206ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 469\n1/1 - 0s - loss: 1.1168 - _timestamp: 1654007120.0000 - _runtime: 322.0000 - 102ms/epoch - 102ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 470\n1/1 - 0s - loss: 1.5780 - _timestamp: 1654007120.0000 - _runtime: 322.0000 - 170ms/epoch - 170ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 471\n1/1 - 0s - loss: 1.7276 - _timestamp: 1654007121.0000 - _runtime: 323.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 6  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 472\n1/1 - 0s - loss: 1.4619 - _timestamp: 1654007121.0000 - _runtime: 323.0000 - 166ms/epoch - 166ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 7  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 473\n1/1 - 0s - loss: 1.5654 - _timestamp: 1654007121.0000 - _runtime: 323.0000 - 167ms/epoch - 167ms/step\n\n\t\t\t\t++++++++++++  episode: 78  - step: 8  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 474\n1/1 - 0s - loss: 2.5747 - _timestamp: 1654007122.0000 - _runtime: 324.0000 - 114ms/epoch - 114ms/step\n\n\t\t\t\t++++++++++++  episode: 79  - step: 0  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 474\n1/1 - 0s - loss: 1.2305 - _timestamp: 1654007122.0000 - _runtime: 324.0000 - 115ms/epoch - 115ms/step\n\n\t\t\t\t++++++++++++  episode: 79  - step: 1  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 474\n1/1 - 0s - loss: 1.3259 - _timestamp: 1654007123.0000 - _runtime: 325.0000 - 169ms/epoch - 169ms/step\n\n\t\t\t\t++++++++++++  episode: 79  - step: 2  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 474\n1/1 - 0s - loss: 2.1880 - _timestamp: 1654007123.0000 - _runtime: 325.0000 - 124ms/epoch - 124ms/step\n\n\t\t\t\t++++++++++++  episode: 79  - step: 3  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 475\n1/1 - 0s - loss: 1.1564 - _timestamp: 1654007124.0000 - _runtime: 326.0000 - 123ms/epoch - 123ms/step\n\n\t\t\t\t++++++++++++  episode: 79  - step: 4  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 476\n1/1 - 0s - loss: 0.8457 - _timestamp: 1654007124.0000 - _runtime: 326.0000 - 127ms/epoch - 127ms/step\n\n\t\t\t\t++++++++++++  episode: 79  - step: 5  ++++++++++++\n\n\t\t\t\t\t      +++++ Training +++++\n\t=> replay_memory size: 477\n1/1 - 0s - loss: 1.1097 - _timestamp: 1654007125.0000 - _runtime: 327.0000 - 115ms/epoch - 115ms/step\n\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n\n\t\t\t\t++++++++++++  episode: 79  - step: 6  ++++++++++++\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "e4fc5ed9faaf4a9596665fae24d4af7a",
        "source_hash": "1ef4273f",
        "execution_start": 1654007125320,
        "execution_millis": 2860,
        "deepnote_cell_height": 196.375,
        "deepnote_output_heights": [
          21.1875
        ],
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "IG2AUWNUD6E_"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {},
    "orig_nbformat": 2,
    "deepnote_notebook_id": "3cd5af7b025e4f5db90b69aa014e2a7a",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": []
    }
  }
}